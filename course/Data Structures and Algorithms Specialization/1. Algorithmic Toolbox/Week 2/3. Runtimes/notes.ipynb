{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Runtimes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- When breaking down the algorithm's runtime, we want to abstract away the actual fine details of the computer (like looking up values, distributed memory stores etc), and focus our attention on what happens asymptotically\n",
    "    - The idea is that we can treat these as if they are multiplying runtimes by come constant. We can ignore how large these constants are, and focus on our own code implementation\n",
    "\n",
    "- This is where Big-O comes in\n",
    "    - Don't care about actual run times.\n",
    "    - we care about how the run time **scales**. i.e. we are looking at first derivative of run time\n",
    "    - Definition: $f(n) = O(g(n))$ if there exists some constants $N$ and $c$ such that for all $n \\gt N$, $f(n) \\le c \\cdot g(n)$\n",
    "        - Translation: your function $f$ is always bounded above by the function $g$ multplied by some constant\n",
    "\n",
    "- Keep in mind that there are limits to Big O analysis\n",
    "    - It only holds in the limit\n",
    "    - Loses information about constant multiples\n",
    "    - Practically speaking, an algorithm with worse big O performance may even do better than an algorithm with a better one on smaller, more practiaclly sized datasets\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Using Big O\n",
    "    - Multiplicative constants are excluded\n",
    "        - $O(2n) = O(n)$\n",
    "    - Larger exponent gives larger function $n^a \\lt n^b$ for $0 \\lt a \\lt b$\n",
    "        - $n = O(n^2), \\sqrt{n} = O(n)$\n",
    "    - Polynomial is always upward bounded in the limit by exponential\n",
    "        - $n^5 = O(\\sqrt{2}^n)$\n",
    "    - Polynomial is always downward bounded in the limit by logarithm\n",
    "        - $\\log{n}^3 = O(\\sqrt{n})$\n",
    "    - Smaller terms can be excluded\n",
    "        - $n^2 + n = O(n^2)$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Other notation\n",
    "    - Big $\\Omega$: Best case \n",
    "    - Big $\\Theta$: Average case\n",
    "    - Small O: Functions grows strictly slower than $g$\n",
    "        - vs Big O: Function grows no faster than $g$"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
