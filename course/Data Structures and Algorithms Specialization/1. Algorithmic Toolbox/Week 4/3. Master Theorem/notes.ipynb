{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- So far, we've written a bunch of recurrence relations; e.g. $T(N) = T(\\frac{N}{2}) + O(1)$ for binary search\n",
    "\n",
    "- The problem is that, so far, every time we want to check time complexity, we need to create a recurrence tree and sum the amount of work done\n",
    "    - In the polynomial multiplication section, we talked about how the usual multiplication algorithm gives us $4^i$ work at each step, giving us $O(N^2)$\n",
    "    - Karatsuba algorithm lets us do the multiplication in $O(N^{\\log_2(3)})$\n",
    "    - $T(N) = 2T(\\frac{N}{2}) + O(N)$\n",
    "\n",
    "- In place of this recurrence tree, the Master theorem lets us generalise the time complexity of a given recurrence\n",
    "\n",
    "- Master theorem: \n",
    "$$ \n",
    "    \\text{If } T(N) = a \\cdot T(\\left \\lceil \\frac{N}{b} \\right \\rceil) + O(N^d), \\forall a \\ge 0, b \\gt 1, d \\ge 0, \\text{ then: } \\\\ \\\\\n",
    "\n",
    "    T(N) = \\begin{Bmatrix}\n",
    "        O(N^d) & \\text{if } d \\gt \\log_b(a) \\\\\n",
    "        O(N^d \\log N) & \\text{if } d = \\log_b(a) \\\\\n",
    "        O(N^{\\log_b(a)}) & \\text{if } d \\lt \\log_b(a) \\\\\n",
    "    \\end{Bmatrix}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Proof\n",
    "    - Imagine that, at the first step, the problem size is $N$\n",
    "    - For the next steps\n",
    "        - We recursively divide the problem size into parts of size $\\frac{n}{b}$. \n",
    "        - For generality, let's assume we end up with $a$ of these parts.\n",
    "            - Logically, there should be $b$ of them, but there are problems where you can subdivide the problem such that the size can be smaller. So for generality, we'll just say that there are $a$ parts. It is possible that $a=b$ or $a \\neq b$\n",
    "        - If we do keep doing this recursively, at level $i$:\n",
    "            - **Problem Size:** We have problems of size $\\frac{N}{b^i}$\n",
    "            - **Problem Count:** There will be $a^i$ of such problems \n",
    "        - This recursion ends when \n",
    "            - **Problem Size:** the size of the problem $\\frac{N}{b^i} = 1$\n",
    "            - **Problem Count:** And there are $a^i = a^{\\log_b(N)}$  of such problems\n",
    "    - Let's further say that, at the first step, the work done is $O(N^d)$\n",
    "        - At the 2nd step, the work done must be $$a \\cdot O((\\frac{N}{b})^d) = O(N^d) (\\frac{a}{b^d})$$ because there are $a$ parts of size $\\frac{N}{b}$\n",
    "        - At the $i$-th step, work done is $$a^i \\cdot O((\\frac{N}{b^i})^d) = O(N^d) (\\frac{a}{b^d})^i$$\n",
    "        - At the last step, work done is $$a^{\\log_b(N)} \\cdot O((\\frac{N}{b^{\\log_b(N)}})^d) = a^{\\log_b(N)} \\cdot O(1) = O(a^{\\log_b(N)}) = O(N^{\\log_b(a)})$$\n",
    "    - So the total work done in any recursive algorithm is simply\n",
    "    $$ \\sum_{i=0}^{\\log_b(N)} O(N^d) (\\frac{a}{b^d})^i $$\n",
    "    - The summation is simply a geometric series! So \n",
    "    $$ \\sum_{i=0}^{\\log_b(N)} O(N^d) (\\frac{a}{b^d})^i = O(N^d) \\cdot \\frac{1 - (\\frac{a}{b^d})^i}{1 - \\frac{a}{b^d}}$$\n",
    "    - Intuitively, the big-O complexity of this geometric series depends only on the term $\\frac{a}{b^d}$\n",
    "        - **Case 1: $\\frac{a}{b^d} < 1 \\rightarrow \\ln_b(a) < d$**\n",
    "            - $$\\begin{aligned}\n",
    "                \\frac{a}{b^d} &< 1 \\\\\n",
    "                a &< b^d \\\\\n",
    "                \\ln(a) &< d \\ln(b) \\\\\n",
    "                \\frac{\\ln(a)}{\\ln(b)} &< d \\\\\n",
    "                \\ln_b(a) &< d & \\text{change of log base}\n",
    "                \\end{aligned}$$\n",
    "            - Then, the terms of the geometric series get smaller as $i$ increases, and so the series is dominated by the first term $O(N^d)$\n",
    "        - **Case 2: $\\frac{a}{b^d} = 1 \\rightarrow \\ln_b(a) = d$**\n",
    "            - Then $\\frac{a}{b^d} = \\frac{a}{b^{\\ln_b(a)}} = \\frac{a}{a} = 1$\n",
    "            - In this case, the geometric series is \n",
    "            $$\\begin{aligned}\n",
    "                \\sum_{i=0}^{\\log_b(N)} O(N^d) (\\frac{a}{b^d})^i &= \\sum_{i=0}^{\\log_b(N)} O(N^d) \\\\\n",
    "                &= (1 + \\log_b(N)) \\cdot O(N^d) & \\text{summation starts from 0} \\\\\n",
    "                &\\approx O(\\log(N) N^d) & \\text{Removing the 1 and changing the log base just incurs some constant cost, which is ignored}\n",
    "            \\end{aligned}$$\n",
    "        - **Case 3: $\\frac{a}{b^d} > 1 \\rightarrow \\ln_b(a) > d$**\n",
    "            - Then the last term of the geometric series dominates, so the geomtric series becomes \n",
    "            $$\\begin{aligned}\n",
    "                O(N^d) (\\frac{a}{b^d})^{\\log_b(N)} &= O(N^d) (\\frac{a^{\\log_b(N)}}{b^{d \\log_b(N)}}) \\\\\n",
    "                &= O(N^d) (\\frac{a^{\\log_b(N)}}{N^d}) \\\\\n",
    "                &= O(a^{\\log_b(N)}) \\\\\n",
    "                &= O(N^{\\log_b(a)}) \\\\\n",
    "            \\end{aligned}$$\n",
    "    - Taken together, these cases prove the Maaster Theorem"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We'll cover a few examples here to get a hang of this\n",
    "\n",
    "- **Example 1:** \n",
    "    - $T(N) = 4 T(\\frac{N}{2}) + O(N)$\n",
    "        - $a=4, b=2, d=1$\n",
    "        - $\\log_b(a) = \\log_2(4) = 2 > 1 = d$\n",
    "        - By Master theorem, recursion is $O(N^{\\log_4(2)}) = O(N^2)$\n",
    "- **Example 2**\n",
    "    - $T(N) = 3 T(\\frac{N}{2}) + O(N)$\n",
    "        - $a=3, b=2 d=1$\n",
    "        - $\\log_b(a) = \\log_2(3) \\approx 1.585 > d = 1$\n",
    "        - By Master theorem, recursion is $O(N^{\\log_b(a)}) = O(N^{\\log_2(3)}) = O(N^{1.585})$\n",
    "- **Example 3**\n",
    "    - $T(N) = 2 T(\\frac{N}{2}) + O(N)$\n",
    "        - $a=2, b=2 d=1$\n",
    "        - $\\log_b(a) = \\log_2(2) = 1 = d$\n",
    "        - By Master theorem, recursion is $O(\\log (N) \\cdot N^1)$\n",
    "- **Example 4**\n",
    "    - $T(N) = T(\\frac{N}{2}) + O(1)$\n",
    "        - $a=1, b=2 d=0$\n",
    "        - $\\log_b(a) = \\log_2(1) = 0 = d$\n",
    "        - By Master theorem, recursion is $O(\\log (N) \\cdot N^0) = O(\\log N)$\n",
    "- **Example 5**\n",
    "    - $T(N) = 2 T(\\frac{N}{2}) + O(N^2)$\n",
    "        - $a=2, b=2 d=2$\n",
    "        - $\\log_b(a) = \\log_2(2) = 1 < 2 = d$\n",
    "        - By Master theorem, recursion is $O(N^d) = O(N^2)$\n",
    "    \n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
