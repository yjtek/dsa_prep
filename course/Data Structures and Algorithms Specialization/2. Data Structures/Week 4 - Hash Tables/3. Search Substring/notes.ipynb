{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying Hashing: Substring Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In every browser, you can do a `Find` to get to the text you want very quickly, even if the webpage is large. We will explore how we can implement an algorithm that does this!\n",
    "\n",
    "- Problem: Given a text $T$ and string $P$, find all occurrences of $P$ in $T$\n",
    "    - Substring notation: Let $S[i...j]$ be the subsstring of $S$ starting at position $i$ and ending at $j$\n",
    "        - S = 'hashing'\n",
    "        - S[0...3] = 'hash'\n",
    "        - S[4...6] = 'ing'\n",
    "        - S[2...5] = 'shin'\n",
    "    - Inputs: Strings $T$, $P$\n",
    "    - Output: All positions $i$ in $T$ such that $0 \\le i \\le |T| - |P|$ that $T[i ... (i + |P| - 1)] = P$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_find_string(string, substring):\n",
    "    '''\n",
    "    Time complexity: O(N * M), \n",
    "        - You search every position in string with length N\n",
    "        - At each position, you go through every character to check for the substring of length M \n",
    "    '''\n",
    "\n",
    "    substring_len = len(substring)\n",
    "    positions_found = []\n",
    "    for i in range(len(string)-substring_len)+1:\n",
    "        if string[i:i+substring_len] == substring:\n",
    "            positions_found.append(i)\n",
    "    return positions_found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lousy Rabin-Karp Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A more efficient implementation of this substring search using hashing!\n",
    "- Recall how we previously solved it\n",
    "    - We want to compare some pattern $P$ against all substrings $S$ of a string $T$, where every substring has length $|P|$ \n",
    "\n",
    "- Notes\n",
    "    - Assume a hash function $h()$\n",
    "    - If $h(P) \\neq h(S)$, then $P \\neq S$\n",
    "    - If $h(P) = h(S)$, then check if $P = P$\n",
    "    - Use polynomial hash family `Polyhash` discussed in section 2, with some large prime number $\\mathbb{p}$\n",
    "    - The idea is that if $P \\neq S$, then probability of hash collision (i.e. $P(h(P) = h(P)) \\le \\frac{|P|}{\\mathbb{p}}$)\n",
    "        - That is, the collision probabilty is bounded by the length of the pattern divided by the value of the prime number chosen\n",
    "    - So if we choose a large prime number $\\mathbb{p}$, we will almost never have false comparison of strings!\n",
    "\n",
    "    - For a given string with length $|T|$ and pattern with length $|P|$, we search $|T| - |P| + 1$ positions\n",
    "    - Hence, probability of collision is simply $(|T| - |P| + 1) \\cdot \\frac{|P|}{p}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "big_prime_number = 2147462143\n",
    "\n",
    "def PolyHash(string, polynomial=10, prime=1000000007):\n",
    "    string_list = list(string)[::-1]\n",
    "    hash_val = 0\n",
    "    for char in string_list:\n",
    "        hash_val = ((hash_val * polynomial) + ord(char)) % prime\n",
    "    return hash_val\n",
    "\n",
    "def RabinKarp(string, pattern, prime):\n",
    "    '''\n",
    "    This is a poorly implemented RabinKarp algorithm, and serves only to illustrate the idea. It is poor, because it does not actually improve \n",
    "    on the naive approach! We see that it is still O(N*M) time complexity\n",
    "\n",
    "    Time complexity: O(M) + O((N-M+1) * M) + O(q M) ~ O(N * M); \n",
    "        - O(M) from hashing pattern\n",
    "        - O(N-M+1) for the number of loops we need to run, and multiply this by M because in each loop, we hash a substring with length M\n",
    "            - This simplifies to O(N*M) on the basis that N*M > M*M > M \n",
    "        - There is the strange term O(q * M)\n",
    "            - This comes about because we must account for the situation where the hash computes to the same value, and we need to compare the actual \n",
    "            pattern with the substring. Remember, this comparison takes O(M) time, where M is the length of the pattern\n",
    "            - Let's suppose there are q occurences of the pattern in the string\n",
    "            - And we know from the analysis above that the hash collision happens (|T| - |P| + 1) . |P|/p times in total\n",
    "            - If p is large, this term is almost 0 (i.e. collisions unlikely)\n",
    "            - So the total times we incur this cost reduces to q\n",
    "            - Hence, the q * M term\n",
    "            - Since q is probably going to be smaller than N, we assume it drops out in the comparison\n",
    "    Space complexity: O(N) for `positions` array\n",
    "    '''\n",
    "    polynomial = np.random.randint(1, prime)\n",
    "    positions = []\n",
    "\n",
    "    ## Compute hash for pattern: O(M)\n",
    "    pattern_hash = PolyHash(pattern, polynomial, prime) \n",
    "    pattern_len = len(pattern)\n",
    "\n",
    "    ## Looping over length of string - length pattern + 1: O(N - M + 1)\n",
    "    ## In each loop, compute the hash for substring with the same length as pattern: O(M)\n",
    "    ## Total: O((N-M+1) * M) = O(N*M) + O(M^2) + O(M) ~ O(N*M)\n",
    "    for i in range(len(string)-pattern_len):\n",
    "        string_hash = PolyHash(string[i:(i+pattern_len)], prime, polynomial)\n",
    "        if string_hash != pattern_hash:\n",
    "            continue\n",
    "        else:\n",
    "            if string[i:(i+pattern_len)] == pattern:\n",
    "                positions.append(i)\n",
    "            continue\n",
    "    return positions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Better Rabin Karp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In the previous implementation of Rabin-Karp algorithm, we incur a huge cost from computing the hash of each substring. But there is actually a way to optimise this!!\n",
    "\n",
    "- The trick here is that `PolyHash` can actually be written as a recurrance relation. Let's show this:\n",
    "    - Let the string to be hashed be $T$\n",
    "    - We want to check all substrings in $T$ with lengths matching the pattern $P$; that is, check $T[i:i+|P|]$ for every value $i \\le |T| - |P| + 1$\n",
    "    - For each position $i$, representing string $T[i: i+|P|]$, we store the hash value in the i-th value of an array, $H[i]$ \n",
    "    - For polyhash, $H[i] = \\sum_{z=i}^{i+|P|-1} (T[z] \\cdot x^{z-i}) \\mod p$\n",
    "    - For polyhash, $H[i+1] = \\sum_{z=i+1}^{i+|P|} (T[z] \\cdot x^{z-i-1}) \\mod p$\n",
    "    - Rewriting $H[i]$...\n",
    "\n",
    "$$\\begin{aligned}\n",
    "    H[i] &= \\sum_{z=i}^{i+|P|-1} (T[z] \\cdot x^{z-i}) \\mod p \\\\\n",
    "    &= [\\sum_{z=i+1}^{i+|P|} (T[z] \\cdot x^{z-i}) + T[i] - T[i + |P|] \\cdot x^{|P|}] \\mod p \\\\\n",
    "    &= [x \\cdot \\sum_{z=i+1}^{i+|P|} (T[z] \\cdot x^{z-i-1}) + T[i] - T[i + |P|] \\cdot x^{|P|}] \\mod p \\\\\n",
    "    &= [x \\cdot H[i+1] + T[i] - T[i + |P|] \\cdot x^{|P|}] \\mod p \\\\\n",
    "\\end{aligned}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- By rewriting $H[i]$ using $H[i+1]$, notice that:\n",
    "    - $x^{|P|}$ is computed once\n",
    "    - $x$, $T[i]$, $T[i+ |P|]$ are all known values\n",
    "    - And if $H[i+1]$ is known, then the computation of H[i] is computed in $O(1)$!!\n",
    "\n",
    "- Let's implement this efficient Rubin-Karp algorithm\n",
    "    - We simply make use of the recurrence relation to compute all values of $H[i]$\n",
    "    - Once we have the hash in every position, we can simply run the comparison between the substring and the chosen pattern in $O(1)$ time, since no computations are necessary!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def polyhash(string, polynomial=10, prime=1000000007):\n",
    "    '''\n",
    "    Time complexity: O(N) where N is length of `string`\n",
    "    '''\n",
    "    reversed_string_list = list(string)[::-1]\n",
    "    hash_val = 0\n",
    "    for char in reversed_string_list:\n",
    "        hash_val = ((hash_val * polynomial) + ord(char)) % prime\n",
    "    return hash_val\n",
    "\n",
    "def precompute_hash(string, pattern, prime, polynomial):\n",
    "    '''\n",
    "    Time complexity: O(M + M + N - M) = O(M+N) \n",
    "        - O(M) from computing the last valid substring of with same length as pattern\n",
    "        - O(M) from computing x^{length of pattern}\n",
    "        - O(N - M) for looping over all remaining valid substrings\n",
    "        - Therefore\n",
    "    '''\n",
    "    pattern_len = len(pattern)\n",
    "    string_len = len(string)\n",
    "    \n",
    "    hash_arr = [None] * (string_len - pattern_len + 1)\n",
    "    last_valid_substring = string[(len(string)-pattern_len):(len(string))]\n",
    "\n",
    "    ## Compute hash of last substring: O(M)\n",
    "    hash_arr[string_len - pattern_len] = polyhash(last_valid_substring, polynomial, prime)\n",
    "\n",
    "    ## Compute x^{pattern length}: O(M)\n",
    "    x_power_p = 1\n",
    "    for _ in range(pattern_len):\n",
    "        x_power_p = (x_power_p * polynomial) % prime\n",
    "\n",
    "    ## Loop over remaining substrings: O(N - M)\n",
    "    for i in range(string_len - pattern_len - 1, -1, -1):\n",
    "        hash_arr[i] = (polynomial * hash_arr[i+1] + ord(string[i]) - x_power_p * ord(string[i+pattern_len])) % p\n",
    " \n",
    "    return hash_arr\n",
    "\n",
    "def RabinKarpEfficient(string, pattern):\n",
    "    '''\n",
    "    Time complexity: \n",
    "        - O(M) from computing pattern's hash\n",
    "        - O(N+M) for running precompute hash\n",
    "        - O(N-M+1) for looping over all possible substrings\n",
    "            - For each iteration of the loop, if the hashes match, we incur a cost fo compare the substring and pattern: O(M) \n",
    "            - If hashes don't match, then it is just O(1)\n",
    "            - Let's suppose we have `q` matches in total. Then the total work done is O((N-M+1) + q*M). \n",
    "                - If we assume q is small, then average time is O(N-M+1)\n",
    "                - q has maximum value N, so it is possible that work done becomes O((N-M+1) + N*M) = O(N*M) in the worst case\n",
    "    Space complexity:\n",
    "        - O(N) from storing ositions, and storing array of precomputed hashes\n",
    "    '''\n",
    "    prime = 32452843\n",
    "    polynomial = np.random.randint(1, prime)\n",
    "    positions = []\n",
    "\n",
    "    ## Compute pattern hash: O(M)\n",
    "    pattern_hash = polyhash(pattern, prime, polynomial)\n",
    "\n",
    "    ## Precompute all substring hash: O(M+N)\n",
    "    all_substring_hash = precompute_hash(string, pattern, prime, polynomial)\n",
    "\n",
    "    ## Loop over N-M+1 entries in substring hashes, and check for hash equality: O(M+N+1)\n",
    "    for i in range(len(string)-len(pattern)+1):\n",
    "        if all_substring_hash[i] != pattern_hash:\n",
    "            continue\n",
    "        if string[i:(i+len(pattern))] == pattern:\n",
    "            positions.append(i)\n",
    "    \n",
    "    return positions"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
