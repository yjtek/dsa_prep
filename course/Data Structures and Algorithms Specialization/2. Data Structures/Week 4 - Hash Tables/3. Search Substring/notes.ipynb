{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying Hashing: Substring Search"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In every browser, you can do a `Find` to get to the text you want very quickly, even if the webpage is large. We will explore how we can implement an algorithm that does this!\n",
    "\n",
    "- Problem: Given a text $T$ and string $P$, find all occurrences of $P$ in $T$\n",
    "    - Substring notation: Let $S[i...j]$ be the subsstring of $S$ starting at position $i$ and ending at $j$\n",
    "        - S = 'hashing'\n",
    "        - S[0...3] = 'hash'\n",
    "        - S[4...6] = 'ing'\n",
    "        - S[2...5] = 'shin'\n",
    "    - Inputs: Strings $T$, $P$\n",
    "    - Output: All positions $i$ in $T$ such that $0 \\le i \\le |T| - |P|$ that $T[i ... (i + |P| - 1)] = P$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def naive_find_string(string, substring):\n",
    "    '''\n",
    "    Time complexity: O(len(string) * len(substring)), because you search every position in string, and at each position, you go through every character to check for the substring \n",
    "    '''\n",
    "\n",
    "    substring_len = len(substring)\n",
    "    positions_found = []\n",
    "    for i in range(len(string)-substring_len)+1:\n",
    "        if string[i:i+substring_len] == substring:\n",
    "            positions_found.append(i)\n",
    "    return positions_found"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Rabin-Karp Algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- A more efficient implementation of this substring search using hashing!\n",
    "- Recall how we previously solved it\n",
    "    - We want to compare some pattern $P$ against all substrings $S$ of a string $T$, where every substring has length $|P|$ \n",
    "\n",
    "- Notes\n",
    "    - Assume a hash function $h()$\n",
    "    - If $h(P) \\neq h(S)$, then $P \\neq S$\n",
    "    - If $h(P) = h(S)$, then check if $P = P$\n",
    "    - Use polynomial hash family `Polyhash` discussed in section 2, with some large prime number $\\mathbb{p}$\n",
    "    - The idea is that if $P \\neq S$, then probability of hash collision (i.e. $P(h(P) = h(P)) \\le \\frac{|P|}{\\mathbb{p}}$)\n",
    "        - That is, the collision probabilty is bounded by the length of the pattern divided by the value of the prime number chosen\n",
    "    - So if we choose a large prime number $\\mathbb{p}$, we will almost never have false comparison of strings!\n",
    "\n",
    "    - For a given string with length $|T|$ and pattern with length $|P|$, we search $|T| - |P| + 1$ positions\n",
    "    - Hence, probability of collision is simply $(|T| - |P| + 1) \\cdot \\frac{|P|}{p}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "big_prime_number = 2147462143\n",
    "\n",
    "def PolyHash(string, prime, polynomial):\n",
    "    '''\n",
    "    Time complexity: O(N) in the length of the string to be hashed\n",
    "    '''\n",
    "    hash_value = 0\n",
    "    for char in string:\n",
    "        hash_value += ((polynomial * hashvalue) + ord(char)) % prime\n",
    "    return hash_value\n",
    "\n",
    "def RabinKarp(string, pattern, prime):\n",
    "    '''\n",
    "    This is a poorly implemented RabinKarp algorithm, and serves only to illustrate the idea. It is poor, because it does not actually improve on the naive approach! We see that it is still O(N*M) time complexity\n",
    "\n",
    "    Time complexity: O(N * M) + O(q M) = O(N * M); \n",
    "        - O(N) because we loop over the string to be compared\n",
    "        - O(M) for the length of the pattern, which we do once in every loop to compute Polyhash\n",
    "        - There is the strange term O(q * M)\n",
    "            - This comes about because we must account for the situation where the hash computes to the same value, and we need to compare the actual pattern with the substring. Remember, this comparison takes O(M) time, where M is the length of the pattern\n",
    "            - Let's suppose there are q occurences of the pattern in the string\n",
    "            - And we know from the analysis above that the hash collision happens (|T| - |P| + 1) . |P|/p times in total\n",
    "            - If p is large, this term is almost 0 (i.e. collisions unlikely)\n",
    "            - So the total times we incur this cost reduces to q\n",
    "            - Hence, the q * M term\n",
    "            - Since q is probably going to be smaller than N, we assume it drops out in the comparison\n",
    "    Space complexity: O(N) for `positions` array\n",
    "    '''\n",
    "    polynomial = np.random.randint(1, prime)\n",
    "    positions = []\n",
    "\n",
    "    pattern_hash = PolyHash(pattern, prime, polynomial) \n",
    "    pattern_len = len(pattern)\n",
    "\n",
    "    for i in range(len(string)-pattern_len):\n",
    "        string_hash = PolyHash(string[i:(i+pattern_len)], prime, polynomial)\n",
    "        if string_hash != pattern_hash:\n",
    "            continue\n",
    "        else:\n",
    "            if string[i:(i+pattern_len)] == pattern:\n",
    "                positions.append(i)\n",
    "            continue\n",
    "    return positions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- In the previous implementation of Rabin-Karp algorithm, we incur a huge cost from computing the hash of each substring. But there is actually a way to optimise this!!\n",
    "\n",
    "- The trick here is that `PolyHash` can actually be written as a recurrance relation. Let's show this:\n",
    "    - Let the string to be hashed be $T$\n",
    "    - We want to check all substrings in $T$ with lengths matching the pattern $P$; that is, check $T[i:i+|P|]$ for every value $i \\le |T| - |P| + 1$\n",
    "    - For each position $i$, representing string $T[i: i+|P|]$, we store the hash value in the i-th value of an array, $H[i]$ \n",
    "    - For polyhash, $H[i] = \\sum_{z=i}^{i+|P|-1} (T[z] \\cdot x^{z-i}) \\mod p$\n",
    "    - For polyhash, $H[i+1] = \\sum_{z=i+1}^{i+|P|} (T[z] \\cdot x^{z-i-1}) \\mod p$\n",
    "    - Rewriting $H[i]$...\n",
    "\n",
    "$$\\begin{aligned}\n",
    "    H[i] &= \\sum_{z=i}^{i+|P|-1} (T[z] \\cdot x^{z-i}) \\mod p \\\\\n",
    "    &= [\\sum_{z=i+1}^{i+|P|} (T[z] \\cdot x^{z-i}) + T[i] - T[i + |P|] \\cdot x^{|P|}] \\mod p \\\\\n",
    "    &= [x \\cdot \\sum_{z=i+1}^{i+|P|} (T[z] \\cdot x^{z-i-1}) + T[i] - T[i + |P|] \\cdot x^{|P|}] \\mod p \\\\\n",
    "    &= [x \\cdot H[i+1] + T[i] - T[i + |P|] \\cdot x^{|P|}] \\mod p \\\\\n",
    "\\end{aligned}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- By rewriting $H[i]$ using $H[i+1]$, notice that:\n",
    "    - $x^{|P|}$ is computed once\n",
    "    - And if $H[i+1]$ is known, then the computation of H[i] is computed in $O(1)$!!\n",
    "\n",
    "- Let's implement this efficient Rubin-Karp algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
