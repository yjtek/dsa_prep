{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phone book implementation with Hashmap"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Having discussed hash tables, maps, and sets, how do we implement a phone book?\n",
    "\n",
    "- Requirements:\n",
    "    1. Add and delete contacts fast\n",
    "    2. Call person by name\n",
    "    3. Determine who is calling given their phonenumber\n",
    "\n",
    "- Quite clearly, requirements 2 and 3 are different look ups, one looks up a number using name as a key, the other looks up a name using number as a key\n",
    "    - So we need 2 maps; `number -> name` and `name -> number`\n",
    "    - Both of these are hash tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Recall the following from previous notes:\n",
    "    - Jargon\n",
    "        - $n$: Number of objects in universe to store\n",
    "        - $m$: Cardinality of hash function\n",
    "        - $c$: Longest chain length\n",
    "    - Asymptotics\n",
    "        - $\\Theta(n+m)$  memory\n",
    "        - $\\Theta(c+1)$  time\n",
    "\n",
    "- We want to keep $m$ and $c$ as small as possible!\n",
    "- We further know that $c \\ge \\frac{n}{m}$\n",
    "    - The smallest $c$ you can get is if you evenly divide all $n$ objects between the $m$ chains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is a good hash function for phone number?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Options\n",
    "    - First 3 digits? Bad, because area code is often the same, so you get large $c$\n",
    "    - Last 3 digits? Might be bad, if many numbers end with `000`\n",
    "    - Random? Good distribution guaranteed, but hash cannot be repeated!\n",
    "\n",
    "- Remember, we want our hash function to be \n",
    "    - Deterministic (i.e. for a given value the computed hash is always the same)\n",
    "    - Fast to compute\n",
    "    - Distributes keys well info different cells\n",
    "    - Few collisions\n",
    "\n",
    "- **Problem**: if the number of possible keys is much bigger than cardinality of the hash function $|S| >> m$, then any hash function $h$ can give you a bad input with collisions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Universal family"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- So if no single hash function that exists can give us the desired case of few collisions, we rely instead on a `universal family` of hash functions\n",
    "    - It is similar to the quicksort idea, where choosing pivot randomly helps us get better performance asymptotically!\n",
    "\n",
    "- We will choose a family (set) of hash functions, then choose a random one from the family\n",
    "\n",
    "- Formally\n",
    "    - Let $U$ be the **universe** i.e. set of all possible keys that we want to hash\n",
    "    - Let $\\mathbb{H} = \\{h: U \\rightarrow \\{0,1,...m-1\\} \\}$ be a set of hash functions\n",
    "    - $\\mathbb{H}$ is a **universal family** if for any two keys $x,y \\in U \\text{and} x \\neq y$, the probability of collision is at most $\\frac{1}{m}$\n",
    "    $$Pr[h(x) = h(y)] \\le \\frac{1}{m}$$\n",
    "    \n",
    "- Intuitively, it just means that if I randomly pick some hash function from this set, and computed h(x) and h(y) for a specific pair (x, y), I have at most $\\frac{1}{m}$ probabilty of collision\n",
    "    - Just as an example, if I uniformly pick a random hash function for x, and another for y, this gives us collision with probability $\\frac{1}{m}$\n",
    "    - Of course this doesn't work, because then the hashing isn't deterministic. It is just to illustrate the idea\n",
    "    - In actual implementation, we will use the same $h$ throughout the algorithm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load Factor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Let's discuss 1 more concept, called the load factor $\\alpha$\n",
    "    - $\\alpha = \\frac{n}{m}$\n",
    "    - It is simply the ratio between the number of objects and cardinality of the hash "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Theorem: If we choose $h$ randomly from universal family, the average length of the longest chain $c$ is $O(1 + \\alpha)$, where $\\alpha=\\frac{n}{m}$ is the load factor of the table\n",
    "    - That is; if $h$ is from the universal family, operations with hash table run on averagein time $O(1 + \\alpha)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- So effectively, our problem reduces to choosing a good $\\alpha$, which we can do by choosing a good $m$\n",
    "    - Ideally, we want $0.5 \\lt \\alpha \\lt 1$\n",
    "    - Once alpha is chosen, the memory we need is automatically $O(m) = O(\\frac{n}{\\alpha}) = O(n)$\n",
    "    - Operations run in $O(1+\\alpha) = O(1)$ time "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dynamic Hash Table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We often don't know the size of $n$ in advance\n",
    "- So instead of wasting space by starting with a big hash table, we can use the idea of dynamic arrays\n",
    "    - Start with hash table of some size, and resize when $\\alpha$ becomes too large\n",
    "    - Then choose a new hash function from universal set, and rehash all objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Rehash(hash_table):\n",
    "    load_factor = len(hash_table.keys()) / \n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
