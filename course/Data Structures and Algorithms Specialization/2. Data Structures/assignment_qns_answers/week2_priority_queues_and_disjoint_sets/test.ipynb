{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext line_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Build Heap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(1, 4), (0, 1), (1, 3)]"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_list = [5,4,3,2,1]\n",
    "\n",
    "def left_child(input_list, index):\n",
    "    child_index = (2*index) + 1\n",
    "    if child_index < len(input_list):\n",
    "        return child_index \n",
    "    else:\n",
    "        return index\n",
    "\n",
    "def right_child(input_list, index):\n",
    "    child_index = (2*index) + 2\n",
    "    if child_index < len(input_list):\n",
    "        return child_index \n",
    "    else:\n",
    "        return index\n",
    "\n",
    "def parent(input_list, index):\n",
    "    return (index-1)//2\n",
    "\n",
    "def sift_down(input_list, index):\n",
    "    curr_index = index\n",
    "    swaps = []\n",
    "\n",
    "    while (input_list[curr_index] > input_list[left_child(input_list, curr_index)]) or (input_list[curr_index] > input_list[right_child(input_list, curr_index)]):  \n",
    "        # print(f\"sift_down: {curr_index=}, {input_list=}, {left_child(input_list, curr_index)=}, {right_child(input_list, curr_index)=}\")\n",
    "        swap_index = left_child(input_list, curr_index) if input_list[left_child(input_list, curr_index)] < input_list[right_child(input_list, curr_index)] else right_child(input_list, curr_index)\n",
    "\n",
    "        input_list[curr_index], input_list[swap_index] = input_list[swap_index], input_list[curr_index]\n",
    "        swaps.append((curr_index, swap_index))\n",
    "        \n",
    "        curr_index = swap_index\n",
    "        # print(f\"sift_down: {input_list=}\")\n",
    "    return swaps\n",
    "\n",
    "def heapify(input_list):\n",
    "    start_index = len(input_list)//2\n",
    "    swaps = []\n",
    "    for index in range(start_index, -1, -1):\n",
    "        # print(f\"Heapify: {index=}, {input_list=}\")\n",
    "        additional_swaps = sift_down(input_list, index)\n",
    "        swaps.extend(additional_swaps)\n",
    "        # print(f\"Heapify: {index=}, {input_list=}\")\n",
    "    \n",
    "    return swaps\n",
    "\n",
    "heapify(input_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Job Queue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Design\n",
    "    - Queue to contain all jobs \n",
    "    - Priority queue (MinHeap) to contain all threads\n",
    "    - Each element of MinHeap will contain a thread ID and a next_time_available attribute\n",
    "        - Heapify using next_time_available\n",
    "        - Break ties using thread ID\n",
    "\n",
    "    - For each job in queue\n",
    "        - ChangePriority for the root node\n",
    "            - Update next_time_available = next_time_available + job time\n",
    "        - Heapify\n",
    "        - Store thread ID and start time as a tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 0),\n",
       " (1, 0),\n",
       " (2, 0),\n",
       " (3, 0),\n",
       " (0, 1),\n",
       " (1, 1),\n",
       " (2, 1),\n",
       " (3, 1),\n",
       " (0, 2),\n",
       " (1, 2),\n",
       " (2, 2),\n",
       " (3, 2),\n",
       " (0, 3),\n",
       " (1, 3),\n",
       " (2, 3),\n",
       " (3, 3),\n",
       " (0, 4),\n",
       " (1, 4),\n",
       " (2, 4),\n",
       " (3, 4)]"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import namedtuple\n",
    "from dataclasses import dataclass\n",
    "import math\n",
    "\n",
    "@dataclass\n",
    "class Thread:\n",
    "    thread_id: int\n",
    "    next_available_time: int\n",
    "\n",
    "    def __repr__(self):\n",
    "        return f'(id={self.thread_id}, {self.next_available_time})'\n",
    "\n",
    "def left_child(index):\n",
    "    child_index = (2*index) + 1\n",
    "    return child_index\n",
    "\n",
    "def right_child(index):\n",
    "    child_index = (2*index) + 2\n",
    "    if child_index < len(pqueue):\n",
    "        return child_index\n",
    "    return child_index\n",
    "\n",
    "def sift_down(index, pqueue, verbose=False):\n",
    "    curr_index = index\n",
    "\n",
    "    while True:\n",
    "        # if verbose:\n",
    "        #     print('='*50)\n",
    "        #     print('sift_down')\n",
    "        #     print(f\"{curr_index=}, {left_child_index=}, {right_child_index=}, {pqueue=}\")\n",
    "\n",
    "        left_child_index = left_child(curr_index) if left_child(curr_index) < len(pqueue) else None\n",
    "        right_child_index = right_child(curr_index) if right_child(curr_index) < len(pqueue) else None\n",
    "\n",
    "        if (left_child_index is None) and (right_child_index is None):\n",
    "            return\n",
    "\n",
    "        compare_index = [x for x in [curr_index, left_child_index, right_child_index] if x is not None]\n",
    "\n",
    "        ordered_index = sorted(\n",
    "            compare_index,\n",
    "            key = lambda i: [pqueue[i].next_available_time, pqueue[i].thread_id]\n",
    "        )\n",
    "        \n",
    "        # if verbose:\n",
    "        #     print(f\"{ordered_index=}\")\n",
    "\n",
    "        if ordered_index[0] == curr_index:\n",
    "            return\n",
    "        else:\n",
    "            pqueue[curr_index], pqueue[ordered_index[0]] = pqueue[ordered_index[0]], pqueue[curr_index]\n",
    "            curr_index = ordered_index[0]\n",
    "        \n",
    "def heapify(pqueue, verbose=False):\n",
    "    start_index = (len(pqueue)-1)//2\n",
    "    for index in range(start_index, -1, -1):\n",
    "        sift_down(index, pqueue, verbose)\n",
    "    return pqueue\n",
    "\n",
    "n_workers = 4\n",
    "jobs = [1]*20\n",
    "pqueue = [Thread(i, 0) for i in range(n_workers)]\n",
    "\n",
    "def assign_jobs(n_workers, jobs, pqueue, verbose=False):\n",
    "\n",
    "    job_queue = jobs\n",
    "    process_log = []\n",
    "    heapify(pqueue, verbose)\n",
    "\n",
    "    for job_time_taken in job_queue:\n",
    "        if verbose:\n",
    "            print('='*50)\n",
    "            print('assign_jobs')\n",
    "            print([(x.thread_id, x.next_available_time) for x in pqueue])\n",
    "        \n",
    "        assigned_thread = pqueue[0]\n",
    "        process_log.append((assigned_thread.thread_id, assigned_thread.next_available_time))\n",
    "        assigned_thread.next_available_time += job_time_taken\n",
    "        \n",
    "        if verbose:\n",
    "            print([(x.thread_id, x.next_available_time) for x in pqueue])\n",
    "        heapify(pqueue, verbose)\n",
    "        if verbose:\n",
    "            print([(x.thread_id, x.next_available_time) for x in pqueue])\n",
    "    \n",
    "    return process_log\n",
    "\n",
    "assign_jobs(n_workers, jobs, pqueue, verbose=False)\n",
    "\n",
    "# # heapify([])\n",
    "# # thread_prio_queue\n",
    "# process_log\n",
    "# pqueue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Merging tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Each table x has some count of rows x.rows\n",
    "- There are $n$ such tables\n",
    "- We do $m$ operations to merge these tables\n",
    "- Return the size of the largest table at the end of each operation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "class Database:\n",
    "    def __init__(self, row_counts):\n",
    "        self.row_counts = row_counts\n",
    "        self.max_row_count = max(row_counts)\n",
    "        n_tables = len(row_counts)\n",
    "        self.ranks = [1] * n_tables\n",
    "        self.parents = list(range(n_tables))\n",
    "\n",
    "    def merge(self, src, dst, verbose=False):\n",
    "        # if verbose:\n",
    "        #     print('='*50)\n",
    "        #     print(f\"{(src, dst)=}\")\n",
    "        #     print(f\"{self.row_counts=}\")\n",
    "        #     print(f\"{self.ranks=}\")\n",
    "        #     print(f\"{self.parents=}\")\n",
    "\n",
    "        src_parent = self.get_parent(src)\n",
    "        dst_parent = self.get_parent(dst)\n",
    "\n",
    "        if src_parent == dst_parent:\n",
    "            return False\n",
    "\n",
    "        if self.ranks[src_parent] > self.ranks[dst_parent]:\n",
    "            self.parents[dst_parent] = src_parent\n",
    "            self.row_counts[src_parent] += self.row_counts[dst_parent]\n",
    "            self.row_counts[dst_parent] = 0\n",
    "            if self.max_row_count < self.row_counts[src_parent]:\n",
    "                self.max_row_count = self.row_counts[src_parent]\n",
    "        else:\n",
    "            self.parents[src_parent] = dst_parent\n",
    "            self.row_counts[dst_parent] += self.row_counts[src_parent]\n",
    "            self.row_counts[src_parent] = 0\n",
    "            if self.max_row_count < self.row_counts[dst_parent]:\n",
    "                self.max_row_count = self.row_counts[dst_parent]\n",
    "            if self.ranks[src_parent] == self.ranks[dst_parent]:\n",
    "                self.ranks[dst_parent] += 1    \n",
    "        \n",
    "        # if verbose:\n",
    "        #     print(f\"{(src, dst)=}\")\n",
    "        #     print(f\"{self.row_counts=}\")\n",
    "        #     print(f\"{self.ranks=}\")\n",
    "        #     print(f\"{self.parents=}\")\n",
    "\n",
    "        return True\n",
    "\n",
    "    def get_parent(self, table):\n",
    "        # find parent and compress path\n",
    "        curr_table = table\n",
    "        path = []\n",
    "\n",
    "        while curr_table != self.parents[curr_table]:\n",
    "            path.append(curr_table)\n",
    "            curr_table = self.parents[curr_table]\n",
    "        \n",
    "        for node in path:\n",
    "            self.parents[node] = curr_table\n",
    "\n",
    "        return curr_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "# del Database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000, 10000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-09 s\n",
      "\n",
      "Total time: 6e-06 s\n",
      "File: /var/folders/sz/cgf6qmyj36bcgkz0rn5dphyw0000gr/T/ipykernel_78827/3898043228.py\n",
      "Function: merge at line 11\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "    11                                               def merge(self, src, dst, verbose=False):\n",
      "    12                                                   # if verbose:\n",
      "    13                                                   #     print('='*50)\n",
      "    14                                                   #     print(f\"{(src, dst)=}\")\n",
      "    15                                                   #     print(f\"{self.row_counts=}\")\n",
      "    16                                                   #     print(f\"{self.ranks=}\")\n",
      "    17                                                   #     print(f\"{self.parents=}\")\n",
      "    18                                           \n",
      "    19         1       4000.0   4000.0     66.7          src_parent = self.get_parent(src)\n",
      "    20         1       2000.0   2000.0     33.3          dst_parent = self.get_parent(dst)\n",
      "    21                                           \n",
      "    22         1          0.0      0.0      0.0          if src_parent == dst_parent:\n",
      "    23         1          0.0      0.0      0.0              return False\n",
      "    24                                           \n",
      "    25                                                   if self.ranks[src_parent] > self.ranks[dst_parent]:\n",
      "    26                                                       self.parents[dst_parent] = src_parent\n",
      "    27                                                       self.row_counts[src_parent] += self.row_counts[dst_parent]\n",
      "    28                                                       self.row_counts[dst_parent] = 0\n",
      "    29                                                       if self.max_row_count < self.row_counts[src_parent]:\n",
      "    30                                                           self.max_row_count = self.row_counts[src_parent]\n",
      "    31                                                   else:\n",
      "    32                                                       self.parents[src_parent] = dst_parent\n",
      "    33                                                       self.row_counts[dst_parent] += self.row_counts[src_parent]\n",
      "    34                                                       self.row_counts[src_parent] = 0\n",
      "    35                                                       if self.max_row_count < self.row_counts[dst_parent]:\n",
      "    36                                                           self.max_row_count = self.row_counts[dst_parent]\n",
      "    37                                                       if self.ranks[src_parent] == self.ranks[dst_parent]:\n",
      "    38                                                           self.ranks[dst_parent] += 1    \n",
      "    39                                                   \n",
      "    40                                                   # if verbose:\n",
      "    41                                                   #     print(f\"{(src, dst)=}\")\n",
      "    42                                                   #     print(f\"{self.row_counts=}\")\n",
      "    43                                                   #     print(f\"{self.ranks=}\")\n",
      "    44                                                   #     print(f\"{self.parents=}\")\n",
      "    45                                           \n",
      "    46                                                   return True"
     ]
    }
   ],
   "source": [
    "# n_tables, n_queries = 6,4\n",
    "# counts = [10,0,5,0,3,3]\n",
    "# # ops = [(3,5), (2,4), (1,4), (5,4), (5,3)] \n",
    "# ops = [(6,6),(6,5),(5,4),(4,3)] \n",
    "\n",
    "import numpy as np\n",
    "n_tables = np.random.randint(10_000, 10_001, 1)[0]\n",
    "n_queries = np.random.randint(10_000, 10_001, 1)[0]\n",
    "counts = list(np.random.randint(1, 10_000, n_tables))\n",
    "ops = [tuple(np.random.randint(1, n_tables, 2)) for _ in range(n_queries)]\n",
    "print(f'{n_tables}, {n_queries}')\n",
    "\n",
    "assert len(counts) == n_tables\n",
    "db = Database(counts)\n",
    "\n",
    "for i in range(n_queries):\n",
    "    dst, src = ops[i]\n",
    "    \n",
    "    %lprun -f Database.merge db.merge(dst - 1, src - 1, verbose=False)\n",
    "    \n",
    "    # db.merge(dst - 1, src - 1, verbose=False)\n",
    "    # print(db.max_row_count)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
