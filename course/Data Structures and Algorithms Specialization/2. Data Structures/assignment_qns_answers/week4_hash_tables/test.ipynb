{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Phone Book"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Qn Summary:\n",
    "    - The ask here is to create a function to be utilised by a phone book called `process_queries`\n",
    "    - This phone book is expected to map numbers to names\n",
    "    - 3 operations are requested\n",
    "        - `add`: given a number and name, add a contact\n",
    "        - `find`: given a number, return the name if it exists, else return not found\n",
    "        - `del`: removes a number from the map\n",
    "\n",
    "- Approach:\n",
    "    - To solve this, simply ensure that the phone book implementation gives O(1) lookup (i.e. hashmap, implemented as `dict()` in Python)\n",
    "    - Nothing else is needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Query:\n",
    "    def __init__(self, query):\n",
    "        self.type = query[0]\n",
    "        self.number = int(query[1])\n",
    "        if self.type == 'add':\n",
    "            self.name = query[2]\n",
    "\n",
    "def read_queries():\n",
    "    n = int(input())\n",
    "    return [Query(input().split()) for i in range(n)]\n",
    "\n",
    "def write_responses(result):\n",
    "    print('\\n'.join(result))\n",
    "\n",
    "def process_queries(queries):\n",
    "    result = []\n",
    "    # Keep list of all existing (i.e. not deleted yet) contacts.\n",
    "    contacts = []\n",
    "    for cur_query in queries:\n",
    "        if cur_query.type == 'add':\n",
    "            # if we already have contact with such number,\n",
    "            # we should rewrite contact's name\n",
    "            for contact in contacts:\n",
    "                if contact.number == cur_query.number:\n",
    "                    contact.name = cur_query.name\n",
    "                    break\n",
    "            else: # otherwise, just add it\n",
    "                contacts.append(cur_query)\n",
    "        elif cur_query.type == 'del':\n",
    "            for j in range(len(contacts)):\n",
    "                if contacts[j].number == cur_query.number:\n",
    "                    contacts.pop(j)\n",
    "                    break\n",
    "        else:\n",
    "            response = 'not found'\n",
    "            for contact in contacts:\n",
    "                if contact.number == cur_query.number:\n",
    "                    response = contact.name\n",
    "                    break\n",
    "            result.append(response)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "queries = [\n",
    "    'add 911 police',\n",
    "    'add 76213 Mom',\n",
    "    'add 17239 Bob',\n",
    "    'find 76213',\n",
    "    'find 910',\n",
    "    'find 911',\n",
    "    'del 910',\n",
    "    'del 911',\n",
    "    'find 911',\n",
    "    'find 76213',\n",
    "    'add 76213 daddy',\n",
    "    'find 76213',\n",
    "]\n",
    "queries = [Query(query_str.split()) for query_str in queries]\n",
    "\n",
    "def process_queries(queries):\n",
    "    results = []\n",
    "    contacts = {}\n",
    "    for query in queries:\n",
    "        if query.type == 'add':\n",
    "            contacts[query.number] = query.name\n",
    "        elif query.type == 'find':\n",
    "            if query.number in contacts:\n",
    "                results.append(contacts.get(query.number))\n",
    "            else:\n",
    "                results.append('not found')\n",
    "        elif query.type == 'del':\n",
    "            if query.number in contacts:\n",
    "                del contacts[query.number]\n",
    "        else:\n",
    "            raise ValueError('Operation must be `add`, `find`, or `del`')\n",
    "\n",
    "    return results\n",
    "\n",
    "process_queries(queries)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Hashing with chains"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Summary:\n",
    "    - In most hashing schemes, there must be a way to deal with multiple objects with the same hash. That is, if string A and string B have the same hash, adding B should not overwrite A\n",
    "        - If we go with the implementation in Q1, that will definitely happen\n",
    "    - In this question, we do this by simply modifying the value stored in the map to an array (list) instead of a single value, which we call a chain. \n",
    "        - So in the event of collision, values are appended in the array instead of overwritten\n",
    "        - When looking up a new value, we simply go to the appropriate chain and iterate through all values there\n",
    "    - Task\n",
    "        - Implement the following hashmap functions while preserving the O(1) look-up of a hashmap:\n",
    "            - `add`: Given a string, hash it and add to the appropriate chain\n",
    "            - `check`: Given an integer representing a chain ID, return all values in the chain as a string\n",
    "            - `find`: Given a string, return 'yes' if value exists in the hashmap, else 'no'\n",
    "            - `del`: Given a string, remove value from hashmap if it exists\n",
    "    \n",
    "- Approach:\n",
    "    - To implement hashing with chain, we simply use a standard python dictionary, with a list as the array\n",
    "        - This preserves the O(1) lookup speed of the hashmap, while handling hash collisions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HellO world\n",
      "no\n",
      "yes\n",
      "HellO\n",
      "GooD luck\n"
     ]
    }
   ],
   "source": [
    "class Query:\n",
    "\n",
    "    def __init__(self, query: list[str]) -> None:\n",
    "        self.type: str= query[0]\n",
    "        if self.type == 'check':\n",
    "            self.ind = int(query[1])\n",
    "        else:\n",
    "            self.s: str = query[1]\n",
    "\n",
    "class QueryProcessor:\n",
    "    _multiplier = 263\n",
    "    _prime = 1000000007\n",
    "\n",
    "    def __init__(self, bucket_count):\n",
    "        self.bucket_count = bucket_count\n",
    "        # store all strings in one list\n",
    "        self.elems = []\n",
    "\n",
    "    def _hash_func(self, s):\n",
    "        ans = 0\n",
    "        for c in reversed(s):\n",
    "            ans = (ans * self._multiplier + ord(c)) % self._prime\n",
    "        return ans % self.bucket_count\n",
    "\n",
    "    def write_search_result(self, was_found):\n",
    "        print('yes' if was_found else 'no')\n",
    "\n",
    "    def write_chain(self, chain):\n",
    "        print(' '.join(chain))\n",
    "\n",
    "    def read_query(self):\n",
    "        return Query(input().split())\n",
    "\n",
    "    def process_query(self, query):\n",
    "        if query.type == \"check\":\n",
    "            # use reverse order, because we append strings to the end\n",
    "            self.write_chain(cur for cur in reversed(self.elems) if self._hash_func(cur) == query.ind)\n",
    "        else:\n",
    "            try:\n",
    "                ind = self.elems.index(query.s)\n",
    "            except ValueError:\n",
    "                ind = -1\n",
    "            if query.type == 'find':\n",
    "                self.write_search_result(ind != -1)\n",
    "            elif query.type == 'add':\n",
    "                if ind == -1:\n",
    "                    self.elems.append(query.s)\n",
    "            else:\n",
    "                if ind != -1:\n",
    "                    self.elems.pop(ind)\n",
    "\n",
    "    def process_queries(self):\n",
    "        n = int(input())\n",
    "        for i in range(n):\n",
    "            self.process_query(self.read_query())\n",
    "\n",
    "queries = [\n",
    "    'add world',\n",
    "    'add HellO',\n",
    "    'check 4',\n",
    "    'find World',\n",
    "    'find world',\n",
    "    'del world',\n",
    "    'check 4',\n",
    "    'del HellO',\n",
    "    'add luck',\n",
    "    'add GooD',\n",
    "    'check 2',\n",
    "    'del good',\n",
    "]\n",
    "\n",
    "bucket_count = 5\n",
    "proc = QueryProcessor(bucket_count)\n",
    "for query in queries:\n",
    "    # print('='*50)\n",
    "    # print(query)\n",
    "    proc.process_query(Query(query.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "no\n",
      "yes\n",
      "yes\n",
      "no\n",
      "\n",
      "add help\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from collections import deque\n",
    "\n",
    "class Query:\n",
    "    def __init__(self, query):\n",
    "        self.type = query[0]\n",
    "        if self.type == 'check':\n",
    "            self.chain_index = int(query[1])\n",
    "        else:\n",
    "            self.string = query[1]\n",
    "\n",
    "class QueryProcessor:\n",
    "    def __init__(self, m) -> None:\n",
    "        self.bucket_counts = m\n",
    "        self.prime = int(1e9 + 7)\n",
    "        self.base = 263\n",
    "        self.hash_table_with_chain = {k: deque() for k in range(m)}\n",
    "        \n",
    "        self.result = []\n",
    "        \n",
    "    def _write_search_result(self, was_found) -> None:\n",
    "        print('yes' if was_found else 'no')\n",
    "\n",
    "    def _write_chain(self, chain) -> None:\n",
    "        print(' '.join(chain))\n",
    "\n",
    "    def _read_query(self) -> Query:\n",
    "        return Query(input().split())\n",
    "\n",
    "    def polyhash(self, s) -> int:\n",
    "            \n",
    "        hashval = 0\n",
    "        for char in s[::-1]:\n",
    "            hashval = (\n",
    "                ((hashval * self.base) % self.prime) + ord(char)\n",
    "            ) % self.prime\n",
    "        return hashval % self.bucket_counts\n",
    "    \n",
    "    def process_query(self, query) -> None:\n",
    "        if query.type == \"check\":\n",
    "            # use reverse order, because we append strings to the end\n",
    "            self._write_chain(\n",
    "                self.hash_table_with_chain.get(query.chain_index, deque())\n",
    "            )\n",
    "        else:\n",
    "            index = self.polyhash(query.string)\n",
    "            if query.type == 'add':\n",
    "                if query.string not in self.hash_table_with_chain[index]:\n",
    "                    self.hash_table_with_chain[index].appendleft(query.string) \n",
    "            if query.type == 'find':\n",
    "                self._write_search_result(query.string in self.hash_table_with_chain[index])\n",
    "            if query.type == 'del':\n",
    "                if query.string in self.hash_table_with_chain[index]:\n",
    "                    self.hash_table_with_chain[index].remove(query.string)\n",
    "\n",
    "    def process_queries(self):\n",
    "        n = int(input())\n",
    "        for _ in range(n):\n",
    "            self.process_query(self._read_query())\n",
    "\n",
    "queries = [\n",
    "    'add world',\n",
    "    'add HellO',\n",
    "    'check 4',\n",
    "    'find World',\n",
    "    'find world',\n",
    "    'del world',\n",
    "    'check 4',\n",
    "    'del HellO',\n",
    "    'add luck',\n",
    "    'add GooD',\n",
    "    'check 2',\n",
    "    'del good',\n",
    "]\n",
    "\n",
    "# bucket_count = 5\n",
    "# proc = QueryProcessor(bucket_count)\n",
    "# for query in queries:\n",
    "#     proc.process_query(Query(query.split()))\n",
    "\n",
    "queries = [\n",
    "    'add test',\n",
    "    'add test',\n",
    "    'find test',\n",
    "    'del test',\n",
    "    'find test',\n",
    "    'find Test',\n",
    "    'add Test',\n",
    "    'find Test',\n",
    "]\n",
    "# bucket_count = 4\n",
    "# proc = QueryProcessor(bucket_count)\n",
    "# for query in queries:\n",
    "#     proc.process_query(Query(query.split()))\n",
    "\n",
    "queries = [\n",
    "    'check 0',\n",
    "    'find help',\n",
    "    'add help',\n",
    "    'add del',\n",
    "    'add add',\n",
    "    'find add',\n",
    "    'find del',\n",
    "    'del del',\n",
    "    'find del',\n",
    "    'check 0',\n",
    "    'check 1',\n",
    "    'check 2',\n",
    "]\n",
    "bucket_count = 3\n",
    "proc = QueryProcessor(bucket_count)\n",
    "for query in queries:\n",
    "    proc.process_query(Query(query.split()))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Find pattern in text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Summary:\n",
    "    - Given 2 strings `text` and `pattern`, find the start index of all occurrences of `pattern` in `text`\n",
    "        - i.e. In text `abacaba`, starting positions of pattern `aba` are [0, 4]\n",
    "    \n",
    "- Approach:\n",
    "    - Naive approach would be to iterate through the entirety of the text for all substrings of `len(pattern)`, then check if the substrings are equal. \n",
    "        - This approach gives `O(N*M)` complexity, which is horrible\n",
    "    - To do this faster, we use the rolling hash (Rabin Karp) algorithm, and make use of the fact that we can hash consecutive substrings in `text` using a recurrent relation, rather than doing a character by character comparison (See notes in `3. Search Substring`)\n",
    "        - This implementation uses the polyhash hash function, but any linear additive hashing function will allow you to derive a recurrence\n",
    "    - Rabin Karp simplifies time complexity to `O(M+N)` on average, though worst case is still `O(M*N)` (if all positions have collisions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python3\n",
    "def read_input():\n",
    "    return (input().rstrip(), input().rstrip())\n",
    "\n",
    "def print_occurrences(output):\n",
    "    print(' '.join(map(str, output)))\n",
    "\n",
    "def get_occurrences(pattern, text):\n",
    "    return [\n",
    "        i \n",
    "        for i in range(len(text) - len(pattern) + 1) \n",
    "        if text[i:i + len(pattern)] == pattern\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 4]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def polyhash(text, polynomial = 10, prime = 1e9+7) -> float:\n",
    "    '''\n",
    "    Time complexity: O(N) where N is the length of the text\n",
    "    '''\n",
    "\n",
    "    hashval: float = 0\n",
    "    for char in text[::-1]:\n",
    "        hashval: float = (((hashval * polynomial) % prime) + ord(char)) % prime\n",
    "    return hashval\n",
    "\n",
    "def precompute_hash(text, pattern, polynomial = 10, prime = 1e9+7) -> list[float]:\n",
    "    '''\n",
    "    Time complexity: \n",
    "        - O(M) for computing the last item in the substring_hash_store\n",
    "        - O(M) for computing x^p\n",
    "        - O(N-M) for computing the rest of the hash store\n",
    "        - Total: O(M+M+N-M) = O(M+N)\n",
    "    '''\n",
    "    ## Declare an array to hold the hash values of the substrings. \n",
    "    ## The length should be len(text) - len(pattern) + 1\n",
    "    textlen: int = len(text)\n",
    "    patternlen: int = len(pattern)\n",
    "    \n",
    "    count_valid_substrings: int = textlen - patternlen + 1\n",
    "    \n",
    "    substring_hash_store: list[float] = [0.] * count_valid_substrings\n",
    "    \n",
    "    ## Compute hash of last possible substring at the end of text\n",
    "    substring_hash_store[-1] = polyhash(text[count_valid_substrings-1:])\n",
    "\n",
    "    ## Compute x^|P|\n",
    "    x_power_p: float = 1\n",
    "    for _ in range(len(pattern)):\n",
    "        x_power_p: float = (x_power_p * polynomial) % prime\n",
    "\n",
    "    ## Use recursive relation in a loop, to find the value of each \n",
    "    ## substring hash: \n",
    "    ## H[i] = (x * H[i+1] + T[i] - T[i + |P|] * x^|P|) mod p\n",
    "    for i in range(count_valid_substrings-2, -1, -1):\n",
    "        substring_hash_store[i] = (\n",
    "            ((polynomial * substring_hash_store[i+1]) % prime) + \n",
    "            (ord(text[i]) % prime) -\n",
    "            ((ord(text[i + len(pattern)]) * x_power_p) % prime)\n",
    "        ) % prime\n",
    "    \n",
    "    return substring_hash_store \n",
    "\n",
    "def rabin_karp(text, pattern) -> list[int]:\n",
    "    '''\n",
    "    Time complexity: \n",
    "        - O(M) for computing pattern hash\n",
    "        - O(N+M) for precomputing hashes for text\n",
    "        - The loop is slightly complex:\n",
    "            - O((N-M+1)) for loop over all possible substrings\n",
    "            - Assuming `q` hashes match and ignoring collisions, it is possible to incur q*M for each loop to check for string equality\n",
    "            - Total: O(N-M+1 + qM) = O(N-M+1) assuming q is small\n",
    "                - Worst case for q is N, so this can become O(N-M+1 + N*M) = O(N*M)\n",
    "        - Total: O(M+N+M+N-M+1) = O(M+2N+1) = O(M+N)\n",
    "    '''\n",
    "    pattern_hash: float = polyhash(pattern)\n",
    "    precomputed_hash: list[float] = precompute_hash(text, pattern)\n",
    "    result: list[int] = []\n",
    "    for i in range(len(text)-len(pattern)+1):\n",
    "        if precomputed_hash[i] == pattern_hash:\n",
    "            if text[i:(i+len(pattern))] == pattern:\n",
    "                result.append(i)\n",
    "    return result\n",
    "\n",
    "rabin_karp('abacaba', 'aba')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 4]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pattern = 'aba'\n",
    "text = 'abacaba'\n",
    "\n",
    "# polyhash(pattern)\n",
    "# print(precompute_hash(pattern=pattern, text=text))\n",
    "rabin_karp(text, pattern)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Substring equality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Summary:\n",
    "    - Given a string `s`, check if the substrings at indices `a` and `b` of length `l` are the same\n",
    "    \n",
    "- Approach:\n",
    "    - Naively, we can simply compare the strings at `s[a:a+l]` and `s[b:b+l]` directly for equality, which will give us time complexity of `O(l)`\n",
    "        - But imagine if there are multiple queries on the same string `s`\n",
    "        - This will quickly become `O(q * l)`\n",
    "    - So in the event of multiple queries, there is a better way using hashing\n",
    "    - First, let's discuss how to precompute the hash (Note: you can precompute hashes the same way we did it in question 3, but this discusses another approach)\n",
    "        - Let's suppose we have a string `ABCDEFG`\n",
    "        - The corresponding integer values of the string is `1234567` (ordinal value of the letters)\n",
    "        - Let's suppose we want to find the hash value of a given substring `CDE`, which we call $H(CDE)$\n",
    "        - Using polyhash, \n",
    "            $$\\begin{aligned}\n",
    "                H(CDE) &= 3x^2 + 4x + 5 \\\\\n",
    "                H(ABCDE) &= x^4 + 2x^3 + 3x^2 + 4x + 5 \\\\\n",
    "                H(AB) &= x + 2 \\\\ \\\\\n",
    "\n",
    "                H(ABCDE) - x^3 * H(AB) &= x^4 + 2x^3 + 3x^2 + 4x + 5 - x^3[x+2] \\\\\n",
    "                &= x^4 + 2x^3 + 3x^2 + 4x + 5 - x^4 - 2x^3 \\\\\n",
    "                &= 3x^2 + 4x + 5 \\\\\n",
    "                &= H(CDE)\n",
    "            \\end{aligned}$$\n",
    "        - So any substring can be computed in linear time, simply by storing the relevant cumulative hash values! \n",
    "    - Once we have this recurrence, to check if the substrings match at positions $a$ and $b$, we simply check if their hashes computed above match up, which can be done in linear time \n",
    "    - To avoid hash collisions, you can either do a character by character comparison in the event of match, or simply compute multiple hashes to check that they all match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "True\n",
      "False\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "\n",
    "class Solver:\n",
    "    def __init__(self, s) -> None:\n",
    "        self.s: str = s\n",
    "        self.polynomial=10\n",
    "        self.prime1 = 1e9+7\n",
    "        self.prime2 = 1e9+9\n",
    "        self.precompute_hash_1 = self.compute_hash(string=s, polynomial=self.polynomial, prime=self.prime1)\n",
    "        self.precompute_hash_2 = self.compute_hash(string=s, polynomial=self.polynomial, prime=self.prime2)\n",
    "\n",
    "    def _ask(self, a, b, l):\n",
    "        return self.s[a:(a+l)] == self.s[b:(b+l)]\n",
    "    \n",
    "    def polyhash(self, string, polynomial=10, prime=1e9+7):\n",
    "        hashval = 0\n",
    "        for char in string[::-1]:\n",
    "            hashval += (((polynomial * hashval) % prime) + ord(char)) % prime\n",
    "        return hashval\n",
    "    \n",
    "    def compute_hash(self, string, polynomial=10, prime=1e9+7):\n",
    "        precompute_substring_hash = [0.] * (len(string)+1)\n",
    "        for i in range(len(string)):\n",
    "            precompute_substring_hash[i+1] = (\n",
    "                (precompute_substring_hash[i] * polynomial) % prime + ord(string[i])\n",
    "            ) % prime\n",
    "        # print(precompute_substring_hash)\n",
    "        return precompute_substring_hash\n",
    "\n",
    "    def ask(self, a, b, l):\n",
    "        polynomial_multiple1 = (self.polynomial**l) % self.prime1\n",
    "        polynomial_multiple2 = (self.polynomial**l) % self.prime2\n",
    "        \n",
    "        hash1_a = (self.precompute_hash_1[a+l] - (polynomial_multiple1 * self.precompute_hash_1[a]) % self.prime1) % self.prime1\n",
    "        hash2_a = (self.precompute_hash_2[a+l] - (polynomial_multiple2 * self.precompute_hash_2[a]) % self.prime2) % self.prime2\n",
    "\n",
    "        hash1_b = (self.precompute_hash_1[b+l] - (polynomial_multiple1 * self.precompute_hash_1[b]) % self.prime1) % self.prime1\n",
    "        hash2_b = (self.precompute_hash_2[b+l] - (polynomial_multiple2 * self.precompute_hash_2[b]) % self.prime2) % self.prime2\n",
    "        \n",
    "        hash1_match = hash1_a == hash1_b\n",
    "        hash2_match = hash2_a == hash2_b\n",
    "\n",
    "        return True if hash1_match and hash2_match else False\n",
    "\n",
    "# s = sys.stdin.readline()\n",
    "# q = int(sys.stdin.readline())\n",
    "s = 'trololo'\n",
    "solver = Solver(s)\n",
    "queries = [(0,0,7), (2,4,3), (3,5,1), (1,3,2)]\n",
    "\n",
    "for query in queries:\n",
    "    print(solver.ask(query[0],query[1],query[2]))\n",
    "# for i in range(q):\n",
    "# \ta, b, l = map(int, sys.stdin.readline().split())\n",
    "# \tprint(\"Yes\" if solver.ask(a, b, l) else \"No\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Longest common substring"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Summary:\n",
    "    - Given 2 strings `s` and `t`, find substring `w` that is common between `s` and `t` that is the longest among all common substrings\n",
    "    \n",
    "- Approach:\n",
    "    - Naively, we can brute force the entire solution by: \n",
    "        - Let's loop every possible substring length $L$\n",
    "            - Then, loop over all possible substrings in `s` with length $L$. This gives us $O(N - L + 1)$\n",
    "                - Then, loop over all possible substrings in `t` with lenght $L$. This gives us $O(M - L + 1)$\n",
    "                    - For each substring from `s` and `t`, do a character-wise comparison in $O(L)$\n",
    "        - Overall, this gives a total of $O(L * (N-L+1) * (M-L+1) * L) \\approx O(N*M*L^2)$\n",
    "        - Horrible approach\n",
    "    \n",
    "    - There is a better approach!!\n",
    "        - We don't know what the length $l$ of the longest substring may be. So we can use binary search to find it\n",
    "            - i.e. We check for all substrings of length $l = \\frac{\\min(|s|, |t|)}{2}$. If it exists, then we check for values between $l = \\frac{\\min(|s|, |t|)}{2}$ and $l = \\min(|s|,|t|)$\n",
    "                - The idea is, if we don't find a common substring of length $x$, there cannot be a common substring of length larger than $x$\n",
    "            - This gives us $O(\\log(N))$\n",
    "        - For every value of $l$ we want to test: \n",
    "            - Recursively compute the hash values for every substring of length $l$ in `s`\n",
    "                - Store the hash values in a map; the key is the hash, and the value is the index where that substring starts\n",
    "                - Store 2 maps, representing 2 hash functions with different primes, to avoid collision\n",
    "                - For each hashmap, it is done is $O(N-L)$ (see notes on `precompute_hash`)\n",
    "            - Once done for `s`, start computing hashes for substrings in `t`\n",
    "                - For each substring, check if hash value exists exists in the earlier map\n",
    "                - If it matches, store current index from `t` and get index from `s` by calling the hashmap.    \n",
    "                    - The question only asks us to identify the longest common substring, not all instances of longest common substrings\n",
    "                - Then, increment the value of $l$ or return\n",
    "                - This is done in $O(M)$\n",
    "            \n",
    "        - So overall complexity is $O(\\log(\\min{N,M}) * (N-L+M-L))$ which is approximately linear time with a $\\log()$ factor\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "answer_type(i=0, j=4, len=3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys\n",
    "from collections import namedtuple\n",
    "\n",
    "Answer = namedtuple('answer_type', ['i', 'j', 'len'])\n",
    "\n",
    "def solve(s, t):\n",
    "\tans = Answer(0, 0, 0)\n",
    "\tfor i in range(len(s)):\n",
    "\t\tfor j in range(len(t)):\n",
    "\t\t\tfor l in range(min(len(s) - i, len(t) - j) + 1):\n",
    "\t\t\t\tif (l > ans.len) and (s[i:i+l] == t[j:j+l]):\n",
    "\t\t\t\t\tans = Answer(i, j, l)\n",
    "\treturn ans\n",
    "\n",
    "s='cool'\n",
    "t='toolbox'\n",
    "\n",
    "s='aaa'\n",
    "t='bb'\n",
    "\n",
    "s='aabaa'\n",
    "t='babbaab'\n",
    "\n",
    "solve(s,t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "answer_type(i=7, j=6, len=9)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def precompute_cumulative_hash(string, prime):\n",
    "    '''\n",
    "    See Q4 for computation. Basically we use the relation that for string `s`, the hash `H()` of s[2:4] is simply H(s[0:4]) - H(s[0:2]) * x^2\n",
    "    '''\n",
    "    hashvals_arr = [0.] * (len(string)+1)\n",
    "    for i in range(len(string)):\n",
    "        hashvals_arr[i+1] = (((hashvals_arr[i] * POLYNOMIAL) % prime) + ord(string[i])) % prime\n",
    "    return hashvals_arr\n",
    "\n",
    "def compute_substring_hashvals(string, string_cumulative_hash_arr, substring_len, prime):\n",
    "    # substr_hashes = [0.] * (len(string)-substring_len+1)\n",
    "    substr_hash_map = {}\n",
    "    polynomial_term = 1\n",
    "    for _ in range(substring_len):\n",
    "        polynomial_term = (polynomial_term * POLYNOMIAL) % prime\n",
    "\n",
    "    for substring_start_index in range(len(string)-substring_len+1):\n",
    "        substring_end_index = substring_start_index+substring_len\n",
    "        hashval = (\n",
    "            string_cumulative_hash_arr[substring_end_index] - \n",
    "            (string_cumulative_hash_arr[substring_start_index] * polynomial_term)\n",
    "        ) % prime\n",
    "        if hashval in substr_hash_map:\n",
    "            substr_hash_map[hashval].append(substring_start_index) \n",
    "        else:\n",
    "            substr_hash_map[hashval] = [substring_start_index]\n",
    "    return substr_hash_map\n",
    "\n",
    "def get_common_substring_index(string, string_cumulative_hash_arr, hash_to_compare, substring_len, prime):\n",
    "    # substr_hashes = [0.] * (len(string)-substring_len+1)\n",
    "    substr_hash_map = {}\n",
    "    polynomial_term = 1\n",
    "    for _ in range(substring_len):\n",
    "        polynomial_term = (polynomial_term * POLYNOMIAL) % prime\n",
    "\n",
    "    for substring_start_index in range(len(string)-substring_len+1):\n",
    "        substring_end_index = substring_start_index+substring_len\n",
    "        hashval = (\n",
    "            string_cumulative_hash_arr[substring_end_index] - \n",
    "            (string_cumulative_hash_arr[substring_start_index] * polynomial_term)\n",
    "        ) % prime\n",
    "        if hashval in hash_to_compare:\n",
    "            return hash_to_compare.get(hashval)[0], substring_start_index\n",
    "    return -1, -1\n",
    "\n",
    "# s='voteforthegreatalbaniaforyou'\n",
    "# t='choosethegreatalbanianfuture'\n",
    "s='p88yisudhfapoiabcd'\n",
    "t='98y3e9mzj9791habcd'\n",
    "POLYNOMIAL=10\n",
    "PRIME1=1e9+7\n",
    "\n",
    "def solve(s, t):\n",
    "    \n",
    "    max_common_substr_len = min(len(s), len(t))\n",
    "    min_common_substr_len = 0\n",
    "    max_matching_substring_len = 0\n",
    "    string1_match_index = 0\n",
    "    string2_match_index = 0\n",
    "\n",
    "    while max_common_substr_len >= min_common_substr_len:\n",
    "        # print('='*50)\n",
    "        # print(f\"{max_common_substr_len=}, {min_common_substr_len=}\")\n",
    "        check_length = (min_common_substr_len + max_common_substr_len)//2\n",
    "        s_hashval_arr_p1 = precompute_cumulative_hash(s, PRIME1)\n",
    "        t_hashval_arr_p1 = precompute_cumulative_hash(t, PRIME1)\n",
    "\n",
    "        s_substring_hash_p1 = compute_substring_hashvals(s, s_hashval_arr_p1, check_length, PRIME1)\n",
    "        common_substring_string1_index, common_substring_string2_index  = get_common_substring_index(t, t_hashval_arr_p1, s_substring_hash_p1, check_length, PRIME1)\n",
    "        has_common_substring = common_substring_string1_index != -1\n",
    "        # print(s[common_substring_string1_index:(common_substring_string1_index+check_length)], t[common_substring_string2_index:(common_substring_string2_index+check_length)])\n",
    "\n",
    "        if has_common_substring:\n",
    "            max_matching_substring_len = check_length\n",
    "            min_common_substr_len = check_length+1\n",
    "            string1_match_index = common_substring_string1_index\n",
    "            string2_match_index = common_substring_string2_index\n",
    "        else:\n",
    "            max_common_substr_len = check_length-1\n",
    "        # print(f\"{max_common_substr_len=}, {min_common_substr_len=}\")\n",
    "\n",
    "    return Answer(string1_match_index, string2_match_index, max_matching_substring_len)\n",
    "\n",
    "solve(s,t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Pattern matching with mismatches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Summary\n",
    "    - Given strings `t` and `p` and integer `k`\n",
    "    - Assume $|t| = n$ and $|p| = m$ and $m < n$\n",
    "    - Find the number of times that `p` occurs in `t`, with a tolerance for `k` mismatches\n",
    "        - i.e. if `t = 'abcde'`, then `p = abf` occurs 1 time with 1 mismatch. So if `k>=1`, then it occurs 1 time. If `k=0`  (i.e. no mismatch tolerated), then it occurs 0 times "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Approach: \n",
    "    - Hash $p$\n",
    "        - This is done in $O(m)$\n",
    "    - Hash $t$\n",
    "        - This is done in $O(n)$\n",
    "    - Looping over every valid substring in $t$ in $O(n)$\n",
    "        - For each substring, run binary search in $O(\\log(m))$\n",
    "            - For each run of binary search iteration, we compare middle character, and binary search the left/right substrings\n",
    "\n",
    "    - How to apply binary search here?\n",
    "        - Given the precomputed hashes, hash of any substring of $t$ can be computed in $O(1)$ time\n",
    "        - For a given substring of $t$, run binary search to count the number of mismatches\n",
    "            - Check if mid-point characters are equal. If no, add 1 to mismatches\n",
    "            - Check if the hash value at the of the LHS substring of $t$ matches the hash value on the LHS of $p$. If hash match, then don't have to binary search the left string any more\n",
    "            - Do the same for the right\n",
    "            - Break when the count of mismatches exceeds $k$    \n",
    "        - Binary search incurs $O(\\log m)$\n",
    "    - We need to perform binary search $n$ times, across the length of $t$\n",
    "\n",
    "- Time complexity is given as $O(nk \\log n)$, but I'm not super sure if that's correct given the breakdown above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# python3\n",
    "import sys\n",
    "\n",
    "'''\n",
    "Solve the Multiple Approximate Pattern Matching Problem.\n",
    "     Input: A string Text, followed by a collection of strings Patterns, and an integer d.\n",
    "     Output: All positions where one of the strings in Patterns appears as a substring of Text with at most d mismatches.\n",
    "\n",
    "Sample Input:\n",
    "ACATGCTACTTT\n",
    "ATT GCC GCTA TATT\n",
    "1\n",
    "Sample Output:\n",
    "2 4 4 6 7 8 9\n",
    "\n",
    "Theorem: If two strings of length n match with at most d mismatches, then they must share a k-mer of length \n",
    "k=⌊n/(d+1)⌋.\n",
    "\n",
    "We now have the outline of an algorithm for matching a string Pattern of length n to Text with at most d mismatches. We first \n",
    "divide Pattern into d+1 segments of length k=⌊n/(d+1)⌋, called seeds. After finding which seeds match Text exactly (seed \n",
    "detection), we attempt to extend seeds in both directions in order to verify whether Pattern occurs in Text with at most d \n",
    "mismatches (seed extension).\n",
    "'''\n",
    "\n",
    "class SuffixArray:\n",
    "    '''\n",
    "    Build suffix array of the string text and\n",
    "    return a list result of the same length as the text\n",
    "    such that the value result[i] is the index (0-based)\n",
    "    in text where the i-th lexicographically smallest\n",
    "    suffix of text starts.\n",
    "    '''\n",
    "    def __init__(self, text):\n",
    "        self.order = self.buildSuffixArray(text)\n",
    "    \n",
    "    def _input(self):\n",
    "        self.text = sys.stdin.readline().strip()\n",
    "\n",
    "    def sortCharacters(self, S):\n",
    "        l = len(S)\n",
    "        order = [0] * l\n",
    "        count = dict()\n",
    "        for i in range(l):\n",
    "            count[S[i]] = count.get(S[i], 0) + 1\n",
    "        charList = sorted(count.keys())\n",
    "        prevChar = charList[0]\n",
    "        for char in charList[1:]:\n",
    "            count[char] += count[prevChar]\n",
    "            prevChar = char\n",
    "        for i in range(l-1, -1, -1):\n",
    "            c = S[i]\n",
    "            count[c] = count[c] - 1\n",
    "            order[count[c]] = i\n",
    "        return order\n",
    "\n",
    "    def computeCharClasses(self, S, order):\n",
    "        l = len(S)\n",
    "        charClass = [0] * l\n",
    "        charClass[order[0]] = 0\n",
    "        for i in range(1, l):\n",
    "            if S[order[i]] != S[order[i-1]]:\n",
    "                charClass[order[i]] = charClass[order[i-1]] + 1\n",
    "            else:\n",
    "                charClass[order[i]] = charClass[order[i-1]]\n",
    "        return charClass        \n",
    "    \n",
    "    def sortDoubled(self, S, L, order, _class):\n",
    "        sLen = len(S)\n",
    "        count = [0] * sLen\n",
    "        newOrder = [0] * sLen\n",
    "        for i in range(sLen):\n",
    "            count[_class[i]] += 1\n",
    "        for j in range(1, sLen):\n",
    "            count[j] += count[j-1]\n",
    "        for i in range(sLen-1, -1, -1):\n",
    "            start = (order[i]-L+sLen) % sLen\n",
    "            cl = _class[start]\n",
    "            count[cl] -= 1\n",
    "            newOrder[count[cl]] = start\n",
    "        return newOrder\n",
    "    \n",
    "    def updateClasses(self, newOrder, _class, L):\n",
    "        n = len(newOrder)\n",
    "        newClass = [0] * n\n",
    "        newClass[newOrder[0]] = 0\n",
    "        for i in range(1, n):\n",
    "            curr = newOrder[i]\n",
    "            prev = newOrder[i-1]\n",
    "            mid = curr + L\n",
    "            midPrev = (prev + L) % n\n",
    "            if _class[curr] != _class[prev] or _class[mid] != _class[midPrev]:\n",
    "                newClass[curr] = newClass[prev] + 1\n",
    "            else:\n",
    "                newClass[curr] = newClass[prev]\n",
    "        return newClass\n",
    "    \n",
    "    def buildSuffixArray(self, S):\n",
    "        sLen = len(S)\n",
    "        order = self.sortCharacters(S)\n",
    "        _class = self.computeCharClasses(S, order)\n",
    "        L = 1\n",
    "        while L < sLen:\n",
    "            order = self.sortDoubled(S, L, order, _class)\n",
    "            _class = self.updateClasses(order, _class, L)\n",
    "            L = 2 * L\n",
    "        return order\n",
    "\n",
    "class ApproxPatternMatching:\n",
    "    def __init__(self):\n",
    "        #text, patterns, d = self._input()\n",
    "        text, patterns, d = self.readFromFile()\n",
    "        occs = self.findOccurrences(text, patterns, d)\n",
    "        print(' '.join(map(str, sorted(occs))))\n",
    "        f = open('result.txt', 'w')\n",
    "        f.write(' '.join(map(str, sorted(occs))))\n",
    "        f.close()\n",
    "    \n",
    "    def _input(self):\n",
    "        text = sys.stdin.readline().strip()\n",
    "        text = text + '$'\n",
    "        data = sys.stdin.read().strip().split()\n",
    "        patterns = data[:-1]\n",
    "        d = int(data[-1])\n",
    "        return text, patterns, d\n",
    "\n",
    "    def readFromFile(self):\n",
    "        f = open('input.txt', 'r')\n",
    "        data = f.read().strip().split()\n",
    "        text = data[0] + '$'\n",
    "        patterns = data[1:-1]\n",
    "        d = int(data[-1])\n",
    "        return text, patterns, d\n",
    "\n",
    "    def bwtFromSuffixArray(self, text, order, alphabet = ['$', 'A', 'C', 'G', 'T']):\n",
    "        l = len(text)\n",
    "        bwt = [''] * l\n",
    "        for i in range(l):\n",
    "            bwt[i] = text[(order[i]+l-1)%l]\n",
    "\n",
    "        counts = dict()\n",
    "        starts = dict()\n",
    "        for char in alphabet:\n",
    "            counts[char] = [0] * (l + 1)\n",
    "        for i in range(l):\n",
    "            currChar = bwt[i]\n",
    "            for char, count in counts.items():\n",
    "                counts[char][i+1] = counts[char][i]\n",
    "            counts[currChar][i+1] += 1\n",
    "        currIndex = 0\n",
    "        for char in sorted(alphabet):\n",
    "            starts[char] = currIndex\n",
    "            currIndex += counts[char][l]\n",
    "        return bwt, starts, counts\n",
    "        \n",
    "    def approxMatching(self, p1, p2, d):\n",
    "        error = 0\n",
    "        for i in range(len(p1)):\n",
    "            if p1[i] != p2[i]:\n",
    "                error += 1\n",
    "                if error > d:\n",
    "                    return False\n",
    "        return True\n",
    "\n",
    "    def findOccurrences(self, text, patterns, d):\n",
    "        order = SuffixArray(text).order\n",
    "        bwt, starts, counts = self.bwtFromSuffixArray(text, order)        \n",
    "        \n",
    "        occs = []\n",
    "        for pattern in patterns:\n",
    "            currOccs = set()\n",
    "            n = len(pattern)\n",
    "            k = n // (d+1)\n",
    "            seeds = [(pattern[i*k:(i+1)*k], i*k) for i in range(d)] + [(pattern[d*k:n], d*k)]\n",
    "            \n",
    "            for p, offset in seeds:\n",
    "                top = 0\n",
    "                bottom = len(bwt) - 1\n",
    "                currIndex = len(p) - 1\n",
    "                while top <= bottom:\n",
    "                    if currIndex >= 0:\n",
    "                        symbol = p[currIndex]\n",
    "                        currIndex -= 1\n",
    "                        if counts[symbol][bottom+1] - counts[symbol][top] > 0:\n",
    "                            top = starts[symbol] + counts[symbol][top]\n",
    "                            bottom = starts[symbol] + counts[symbol][bottom+1] - 1\n",
    "                        else:\n",
    "                            break\n",
    "                    else:\n",
    "                        for i in range(top, bottom + 1):\n",
    "                            currOccs.add(order[i]-offset)\n",
    "                        break\n",
    "            for occ in currOccs:\n",
    "                if self.approxMatching(text[occ:occ+n], pattern, d):\n",
    "                    occs.append(occ)\n",
    "        return occs\n",
    "    \n",
    "\n",
    "ApproxPatternMatching()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
